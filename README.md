# Neural-Networks-from-Scratch-NumPy-MNIST-
Did this with teachings from **from Samson Zhang**.
This repo built neural networks completely from scratch using just NumPy and trained them on the MNIST dataset.  The goal was to deeply understand how neural networks work under the hood â€” from forward and backward propagation to gradient descent and weight updates. No TensorFlow or PyTorch here, just pure math and code! 

dataset - https://www.kaggle.com/competitions/digit-recognizer/data
